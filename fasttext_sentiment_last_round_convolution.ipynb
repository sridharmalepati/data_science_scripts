{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext sentiment last round convolution",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP6KOhNEwtW2KXZ5IVCVikJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuyguA/data_science_scripts/blob/master/fasttext_sentiment_last_round_convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sXqx9ZC4JO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "b783e08e-8e0d-4afe-e71d-26067e0be8f4"
      },
      "source": [
        "!!pip3 install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting fasttext',\n",
              " '\\x1b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)',\n",
              " '',\n",
              " '\\x1b[K     |████▊                           | 10kB 20.7MB/s eta 0:00:01',\n",
              " '\\x1b[K     |█████████▌                      | 20kB 7.0MB/s eta 0:00:01',\n",
              " '\\x1b[K     |██████████████▎                 | 30kB 8.0MB/s eta 0:00:01',\n",
              " '\\x1b[K     |███████████████████             | 40kB 8.7MB/s eta 0:00:01',\n",
              " '\\x1b[K     |███████████████████████▉        | 51kB 7.4MB/s eta 0:00:01',\n",
              " '\\x1b[K     |████████████████████████████▋   | 61kB 7.8MB/s eta 0:00:01',\n",
              " '\\x1b[K     |████████████████████████████████| 71kB 4.7MB/s ',\n",
              " '\\x1b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)',\n",
              " 'Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (47.1.1)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.4)',\n",
              " 'Building wheels for collected packages: fasttext',\n",
              " '  Building wheel for fasttext (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3014629 sha256=7a1ee2e1f3b8fe715b3746c909cd7d9292e3110dc3a49269fdf4ecb7b4b58b24',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592',\n",
              " 'Successfully built fasttext',\n",
              " 'Installing collected packages: fasttext',\n",
              " 'Successfully installed fasttext-0.9.2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzobhMIbDCel"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlOrTTPNDOJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "34d3accf-fdc2-44bc-beb5-b6f6efa09fd1"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-07 08:17:55--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4506977940 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.tr.300.bin.gz’\n",
            "\n",
            "cc.tr.300.bin.gz    100%[===================>]   4.20G  10.5MB/s    in 6m 56s  \n",
            "\n",
            "2020-06-07 08:24:53 (10.3 MB/s) - ‘cc.tr.300.bin.gz’ saved [4506977940/4506977940]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNN_hKGkDavB"
      },
      "source": [
        "!gzip -d cc.tr.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ynYKIM2DbIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6afe61e-7021-4809-fa3a-7075d73d34d6"
      },
      "source": [
        "m = fasttext.load_model(\"cc.tr.300.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXbX2sPCDbZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bced3708-dcbe-4e41-bb0d-c2121e737385"
      },
      "source": [
        "dir(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_labels',\n",
              " '_words',\n",
              " 'f',\n",
              " 'get_analogies',\n",
              " 'get_dimension',\n",
              " 'get_input_matrix',\n",
              " 'get_input_vector',\n",
              " 'get_label_id',\n",
              " 'get_labels',\n",
              " 'get_line',\n",
              " 'get_meter',\n",
              " 'get_nearest_neighbors',\n",
              " 'get_output_matrix',\n",
              " 'get_sentence_vector',\n",
              " 'get_subword_id',\n",
              " 'get_subwords',\n",
              " 'get_word_id',\n",
              " 'get_word_vector',\n",
              " 'get_words',\n",
              " 'is_quantized',\n",
              " 'labels',\n",
              " 'predict',\n",
              " 'quantize',\n",
              " 'save_model',\n",
              " 'set_args',\n",
              " 'set_matrices',\n",
              " 'test',\n",
              " 'test_label',\n",
              " 'words']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEm98caKDbpf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7B3xFoQrwyg"
      },
      "source": [
        "import re\n",
        "\n",
        "#from emoticon_smiley import replace_smileys\n",
        "\n",
        "opponents = [\"bimcell\", \"pttcell\", \"ttnet\", \"vodafone\", \"avea\", \"netcell\", \"vestelcell\", \"turk telekom\", \"turktelekom\", \"turknet\"]\n",
        "opp_regex = r\"@?(\" + r\"|\".join(opponents) + r\")(\\w+)?\"\n",
        "\n",
        "def replace_ceo(sentence):\n",
        "  sentence = re.sub(r\"(@?Kaan_?Terzio[gğ]lu|\\bkaan\\b)\", \"CEO\", sentence, flags=re.I)\n",
        "  return sentence\n",
        "\n",
        "def replace_opponents(sentence):\n",
        "  sentence = re.sub(opp_regex, \" rakip şirket \", sentence, flags=re.I)\n",
        "  return sentence\n",
        "\n",
        "def replace_self_mentions(sentence):\n",
        "  sentence = re.sub(\"t.?rkcll?\", \"turkcell\", sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_entities(sentence):\n",
        "  sentence = replace_ceo(sentence)\n",
        "  sentence = replace_opponents(sentence)\n",
        "  sentence = replace_self_mentions(sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_dots(sentence):\n",
        "  sentence = sentence.replace(u\"\\u2026\", \"...\").replace(u\"\\u2025\", \"..\").replace(u\"\\u1427\", \".\")\n",
        "  return sentence\n",
        "\n",
        "def replace_brackets(sentence):\n",
        "  sentence = sentence.replace(\"}\", \" \").replace(\"{\", \" \").replace(\"]\", \" \").replace(\"[\", \" \")\n",
        "  return sentence\n",
        "\n",
        "def replace_quotation_marks(sentence):\n",
        "  rlist = [ u\"\\u2018\", u\"\\u201c\", u\"\\u201d\", '\"', u\"\\u0060\", u\"\\u00b4\", u\"\\u2019\"]\n",
        "  for r in rlist:\n",
        "    sentence = sentence.replace(r, \" \")\n",
        "  return sentence\n",
        "\n",
        "def replace_url(sentence):\n",
        "  url_string = r\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\"\n",
        "  return re.sub(url_string, \" websitesi \", sentence)\n",
        "\n",
        "def replace_underscore(sentence):\n",
        "  sentence = re.sub(r\"[.]{3,}\", \"...\", sentence)\n",
        "  sentence = re.sub(r\"(?<=\\s)_(?=\\s)\", \" \", sentence)\n",
        "  sentence = re.sub(r\"(?<=\\w)([,:;])\", r\" \\1\", sentence)\n",
        "  sentence = re.sub(r\"(?<=[\\w\\s])([|<>/-])(?=[\\w\\s])\" , \" \", sentence)\n",
        "  return sentence\n",
        "\n",
        "def process_quotation(sentence):\n",
        "  sentence = re.sub(r\"(?<![.\\d])\\.\", \" .\", sentence)\n",
        "  sentence = re.sub(r\"\\.(?![.\\d])\", \". \", sentence)\n",
        "  sentence = sentence.replace(\"?\", \" ? \").replace(\"!\", \" ! \").replace(\",\", \", \").replace(\"...\", \"... \")\n",
        "  sentence = re.sub(r\"[\\s#\\@&]\", \" \", sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_html(sentence):\n",
        "  sentence = sentence.replace(\"&lt;\", \"<\")\n",
        "  sentence = sentence.replace(\"&gt;\", \">\")\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def preprocess(sentence):\n",
        "  sentence = sentence.strip()\n",
        "  sentence = sentence.lower()\n",
        "  sentence = replace_html(sentence)\n",
        "  sentence = replace_url(sentence)\n",
        "  sentence = replace_entities(sentence)\n",
        "  sentence = replace_dots(sentence)\n",
        "  sentence = replace_brackets(sentence)\n",
        "  sentence = replace_quotation_marks(sentence)\n",
        "  sentence = replace_underscore(sentence)\n",
        "  sentence = process_quotation(sentence)\n",
        "  tokens = sentence.strip().split()\n",
        "  #t = replace_smileys(tokens)\n",
        "  return  tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyi7XqSXsbc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13d13c4b-9217-4112-9c95-8f3434347ee2"
      },
      "source": [
        "preprocess(\"......\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0sc7dmQscCz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZneeHtncUa"
      },
      "source": [
        "sentences = []\n",
        "y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UYyffRNs-nm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5rK794ki4W0"
      },
      "source": [
        "with open(\"all_sentiment_train.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        sentences.append(s)\n",
        "        y.append(int(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMutdd-ToNVR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK77usaFKeco"
      },
      "source": [
        "test_sentences = []\n",
        "test_y = []\n",
        "\n",
        "with open(\"all_twitter_test.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        test_sentences.append(s)\n",
        "        test_y.append(int(res))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBY9ZgrvGdCx"
      },
      "source": [
        "test_cust_sentences = []\n",
        "test_cust_y = []\n",
        "\n",
        "with open(\"all_customer_test.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        test_cust_sentences.append(s)\n",
        "        test_cust_y.append(int(res))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UKsTvB_GH_S"
      },
      "source": [
        "test_twit_sentences = []\n",
        "test_twit_y = []\n",
        "\n",
        "with open(\"all_twitter_test.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        test_twit_sentences.append(s)\n",
        "        test_twit_y.append(int(res))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCQaVHn9s-8b"
      },
      "source": [
        "words = set()\n",
        "for sentence in sequences:\n",
        "    for word in sentence:\n",
        "        words.add(word)\n",
        "\n",
        "for sentence in test_cust_seqs:\n",
        "  for word in sentence:\n",
        "    words.add(word)\n",
        "\n",
        "for sentence in test_twit_seqs:\n",
        "  for word in sentence:\n",
        "    words.add(word)\n",
        "\n",
        "\n",
        "n_words = len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbeg-BB_4PwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c213a83-b25e-40b6-8998-6e4945d4c521"
      },
      "source": [
        "n_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dARL26YSoZDo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIvDF6fcrxW-"
      },
      "source": [
        "sequences = [preprocess(sentence) for sentence in sentences]\n",
        "#test_seqs = [preprocess(t_sentence) for t_sentence in test_sentences]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr1c49tlGyu2"
      },
      "source": [
        "test_cust_seqs = [preprocess(t_sentence) for t_sentence in test_cust_sentences]  \n",
        "test_twit_seqs = [preprocess(t_sentence) for t_sentence in test_twit_sentences]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dAZbSQp5EVe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8FNCtB7xggr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc0cJMg6tvc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42f5f59c-97c3-4d48-a2bb-94907fc13159"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbKDaWOuuMb"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOatna3ZuugK"
      },
      "source": [
        "tok = Tokenizer(n_words+1, lower=True)\n",
        "tok.fit_on_texts(sequences )\n",
        "X_word = tok.texts_to_sequences(sequences)\n",
        "X_word = pad_sequences(X_word, maxlen=MAX_LEN, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrbFZ_tM4Bwp"
      },
      "source": [
        "test_twitter_sequences = tok.texts_to_sequences(test_twit_seqs)\n",
        "X_twitter_test = pad_sequences(test_twitter_sequences, MAX_LEN, padding=\"post\")\n",
        "\n",
        "X_twitter_test = np.array(X_twitter_test)\n",
        "test_twit_y = np.array(test_twit_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iYqbydGtoh"
      },
      "source": [
        "test_cust_sequences = tok.texts_to_sequences(test_cust_seqs)\n",
        "X_cust_test = pad_sequences(test_cust_sequences, MAX_LEN, padding=\"post\")\n",
        "\n",
        "X_cust_test = np.array(X_cust_test)\n",
        "test_cust_y = np.array(test_cust_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Yuza8svgDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "014f4c56-2575-4f17-a6f1-8ac9ff77c08c"
      },
      "source": [
        "max(len(sent) for sent in sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "339"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fva_c95vv7TM"
      },
      "source": [
        "MAX_LEN =350"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkFLUb_9wAfZ"
      },
      "source": [
        "word_index = tok.word_index\n",
        "embed_size=300\n",
        "embedding_matrix = np.zeros((n_words+1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= n_words: continue\n",
        "    embedding_vector = m.get_word_vector(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIoRIdyMxZcp"
      },
      "source": [
        "X_word = np.array(X_word)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9xH4AQdUUmE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLkX6KBVUU5M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUdF55RKUU5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "30efed6b-4882-438f-c7d3-ac2e9a3e3abb"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"wordConv\", histogram_freq=1, write_graph=True, write_images=True, embeddings_freq=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:102: UserWarning: The TensorBoard callback does not support embeddings display when using TensorFlow 2.0. Embeddings-related arguments are ignored.\n",
            "  warnings.warn('The TensorBoard callback does not support '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Ge8TKs1EPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5dee7248-bda8-4ae4-f03d-a690d4015776"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "weight_decay = 1e-4\n",
        "num_filters=64\n",
        "\n",
        "word_in = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "conv = Conv1D(num_filters, 7, activation='relu', padding='same')(x)\n",
        "mp1 = MaxPooling1D(2)(conv)\n",
        "conv1 = Conv1D(num_filters, 7, activation='relu', padding='same')(mp1)\n",
        "mp2 = GlobalMaxPooling1D()(conv1)\n",
        "dp1 = Dropout(0.5)(mp2)\n",
        "dense1  = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(dp1)\n",
        "dense2 = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model = Model(input=word_in, outputs=dense2)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UFJi89o1Lgn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "2d4d5751-67e0-4460-c841-ba7cbca1fb0c"
      },
      "source": [
        "model.fit(X_word,y, batch_size=256,  validation_data= [X_twitter_test, test_twit_y], epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 53746 samples, validate on 451 samples\n",
            "Epoch 1/5\n",
            "53746/53746 [==============================] - 266s 5ms/step - loss: 0.4329 - accuracy: 0.7914 - val_loss: 0.1245 - val_accuracy: 0.9601\n",
            "Epoch 2/5\n",
            "53746/53746 [==============================] - 261s 5ms/step - loss: 0.1439 - accuracy: 0.9528 - val_loss: 0.0404 - val_accuracy: 0.9933\n",
            "Epoch 3/5\n",
            "53746/53746 [==============================] - 262s 5ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0129 - val_accuracy: 0.9978\n",
            "Epoch 4/5\n",
            "53746/53746 [==============================] - 264s 5ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.0076 - val_accuracy: 0.9978\n",
            "Epoch 5/5\n",
            "53746/53746 [==============================] - 263s 5ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0077 - val_accuracy: 0.9978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd265096e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW5nqDiXWCR4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4e7bd1c-a287-4e87-c9a7-cd95eac49bba"
      },
      "source": [
        "results = model.evaluate(X_cust_test, test_cust_y, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2734/2734 [==============================] - 3s 948us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFARbqmzagZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3c05b67-a69e-4f70-d595-5281921ad5b4"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2956139805679698, 0.9261155724525452]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AW5B2043rPS"
      },
      "source": [
        "incorrects = np.nonzero(np.round(model.predict(X_cust_test).reshape((-1,))).astype(int) != test_cust_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Papg1RPG3vC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d6cdc42-c799-4619-a76b-ccfe46eca693"
      },
      "source": [
        "len(incorrects[0]), len(test_cust_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(202, 2734)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlRW2WV3w5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39648683-543d-4b42-8e2c-c6142fca30ee"
      },
      "source": [
        "for i in incorrects[0]:\n",
        "  print(test_cust_sentences[i], \"\\t\", test_cust_y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uzun zamandır kullanıyorum hala murekkep almadım. sankı murekkepı harcamıyor, kokluyor.. \t 1\n",
            "beğenmedim.resimde daha büyüktü. \t 0\n",
            "ÜRÜN GÜZEL FAKAT ÇOK KÜÇÜK VE RESİMDE DAHA GÜZEL GÖRÜNÜYOR \t 0\n",
            "Ürün gayet başarılı okuma ve yazma hızı olarak, 2016 yılında f/p ürünüydü. Ah be döviz kuru sen nelere kadirsin... \t 1\n",
            "yoruma ne gerek var kullanışlı değil yeterlim mi... \t 0\n",
            "ürün güzel ama kurulumu zorladı.kullanma klavuzu ingilizce geldi satıcının dikkat etmesi gereken bir durum \t 1\n",
            "İş görürmü görür ama cok kaliteli değil calışırken demirin sesleri çıkıyor \t 0\n",
            "bu ucret bile cok derim. kokuda ozelliksiz. \t 0\n",
            "Kesinlikle türkçe dublaj göndermiyorlar ona göre sipariş verin. Altyazılı. \t 0\n",
            "Mouse biraz küçük, yetişkinlere için rahatsız edici bir unsur. \t 0\n",
            "Biraz ağır \t 1\n",
            "Kalite düşük , ip ince , \t 0\n",
            "Evet, pazarlama harikası bir ürün. Japonlar yapmış.. Bravo! \t 0\n",
            "Bir farkını göremedim ama hediye olarak gönderildiği için teşekkürler. \t 0\n",
            "Ürün iyi fakat pes ve fifa 16 da sağ analog ile iş göremiyorsunuz onun dışında güzel... \t 0\n",
            "Gönderi süper hızlı ?? ancak bilekliği beğenmedim \t 0\n",
            "yer değişikliğinde 300-400 gr farklılıklar oluyor \t 0\n",
            "Süreyi çok uzatmıyor kısmen başarılı bir ürün. \t 0\n",
            "Ürünü 2 sene önce yarı fiyatına almıştım hala kullanıyorum. \t 1\n",
            "sıcak tutuyo tamam ama terleme yapıyo \t 0\n",
            "ev içi kullanımda daha iyisini bulamazsınız ve kurulumu kolay \t 1\n",
            "Ürün açıklamalarda yazan gibi gerçekten her yüzeyde işliyor. Bu fiyata bu kalite kaçmaz. Ancak kargo biraz geç geldi. \t 1\n",
            "göründüğü gibi..standart \t 1\n",
            "Fİyatına göre iyi oyun oynarken falan ses kasmada işe yarıyor ama profesyoneller için değil. \t 1\n",
            "Sadece yavaş sağlam bi malzeme kullanılmış başarılı \t 1\n",
            "Bir hafta oldu hala kargona ya ürün verilecek. ???? \t 0\n",
            "güzel bir ürün çok da beğenmedim idare eder teşekkürler \t 0\n",
            "Ben size 5 numaranın 126 lık paketini tavsiye ederim. Mega paket. Onlar çok daha avantajlı. Benden söylemesi. \t 0\n",
            "biraz ufak gibi. platformu da çok basit.. biraz daha ucuz olabilir \t 0\n",
            "yumuşaklığı çok iyi ama biraz uzun koparmak gerekiyor. \t 0\n",
            "Ekeani cabuk çiziliyor onun dışında alınabilir \t 1\n",
            "çekinerek aldım fiat ucuz ama kediler beğenmediler.bu yüzden new cat mamasını tavsiye etmiyorum.fiat iyi kalite rezalet \t 0\n",
            "Çok kulanışlı bir yazıcı. 500? olsa yine alırdım. \t 1\n",
            "Biraz fazla esnek.Kapağını kapatmak için biraz uğraşmanız gerekiyor. \t 0\n",
            "Teker çok güzel ama geç geldi. \t 0\n",
            "ürün olarak toz olanlar ile sıvı olanlar tercih edilebilir. Güçlü ve doğal bir ürünse kaçırmayın derim \t 1\n",
            "Fiyatını sürekli arttırmasalar daha iyi olacak. Düşmesini bekleyeceğim. \t 0\n",
            "GÖRÜNDÜĞÜ GİBİ KALİTELİ BİR ÜRÜN KESİNLİKLE TAVSİYE EDERİM. \t 1\n",
            "İş görür. \t 0\n",
            "Aldıktan bir hafta sonra misafirim yerde uyandı. AL MA YIN. \t 0\n",
            "bilezik güzel ama çok ince \t 0\n",
            "Ürün uzun menzili ile tatmin ediyor fakat modemin yanında aldığınız hızı daha uzaklarda full çekse bile beklemeyin. \t 1\n",
            "soylenılenler kadar da super bi urun degıl \t 0\n",
            "Çeşitli yüzeylerde gayet güzel kendi görevini yapıyor. bazı daha pahalı mousları bundan daha kötü çalışıyor \t 1\n",
            "Görseleden daha küçük bir ürün. \t 0\n",
            "Ürün sarımı dışında sıkıntı yok navlundan kurtarmak için katlanarak sarılmış doğal olarak kat yerleri iz yapmış \t 0\n",
            "Karanlıkta, loş ışıkta hiç görünmüyor. Işığını yakmak için yanına gitmek gerekiyor. \t 0\n",
            "bardak oldugunu soylemislerdi kahve ve damak geldii \t 0\n",
            "Ucuz çalışan bir kulaklık istiyorsanız alın gitsin. \t 1\n",
            "Mikrofonu agziniza sokmaniz gerek iyi ses alabilmek icin \t 0\n",
            "Fırsat sitelerinden IMAX dahil olan 3D versiyonunu alabiliyorsunuz, IMAX dışında kullanabilirsiniz.. \t 0\n",
            "Ürün güzel ve hızlı .fakat bazen cihazı takmakta zorlanıyorsun. Flasın u.ç kısımları içeri kaçmakta.puanı ordan kırdım. \t 1\n",
            "Bazı sd kartları formatlamadan çalışmıyor. Fakat bu ürün direkt olarak çalıştı. Teşekkürler. \t 1\n",
            "Ürünüm zamanında ve düzgün teslim edildi. \t 1\n",
            "Beklenenen hemen kesim olsun isteniyor ama 30 dk uğraşıyorsun?? \t 0\n",
            "Kablonun olmayışına dikkat edin bi liralık şeyi koymamışlar neden anlamıyorum \t 1\n",
            "ben kauçuk olacağını sanıyordum. resimden de o izlenim verilmiş.basit bir şey. hoşuma gitmedi \t 0\n",
            "Ürün güzel ama fatura gelmedi \t 1\n",
            "çok küçük ebatlar.kullanisli deyil rengi guzel \t 0\n",
            "sadece biraz ağır.. \t 1\n",
            "Çok kötü değil ama çok iyi cekim gücü yok \t 0\n",
            "INKJETLERDEN HEP KORKARDIM. KORKUMU YENMEME SEBEP OLDU. \t 1\n",
            "Basit bir ürün \t 0\n",
            "F/P Şampiyonu sırf marka diye daha fazla para vermeye gerek yok onlarda çin de üretiliyor \t 1\n",
            "Fena değil \t 1\n",
            "Ben indirimde diye 2 adet aldım dizüstü ve TV için kullandığımda optik algılamada ışık yok direk ışıksız bu süper bişi \t 1\n",
            "fena degil \t 1\n",
            "Note 4 le arasında fark yok hatta Note 4 ün bazı özellikleri daha iyi :) \t 0\n",
            "Benim yaşadığım bölgede internet yavaş olduğu için hızı biraz düşük fakat mağazalarda 200 TL ye satılıyor. \t 1\n",
            "ses guzel ama ben bass seven biri olarak bass beni hic tatmin etmiyor ancak yuruyus yaparken dinlemelik bi kulaklik \t 0\n",
            "F/P ürünü.Çokta bi şey beklemeyin \t 1\n",
            "Sadece eksisi hafif degil biraz agir \t 1\n",
            "Uzunluk iyi ancak eni kısa. İhtiyaç görür. \t 0\n",
            "Bu efsanevi tecrübe için teşekkürler. \t 0\n",
            "Hızlı portatif bir urun ama kablosu biraz daha uzun olabilirdi \t 1\n",
            "Kendime almıştım, görünce oğlumda istedi. \t 1\n",
            "Bu fiyata fazla bence daha iyisi alınabilir \t 0\n",
            "şubat 2016 da aldım gecen ay bozulmustu sağ tuş tıklanmıyordu servise verdim 1 hatfa içinde yenisi verdiler. \t 1\n",
            "Gerçekten hızlı şarj ediyor.Birazcık ağır.Birde nasıl kapanıyor çözemedim daha:) \t 1\n",
            "Ürün güzel ve beğendim. ama güzel paketlenmemişti ve ürün zarar görebilirdi. \t 0\n",
            "kulaklık çıkmadı içinden. telefonu daha kullanmadım ama görntü ve kurulum için kullandığımda tatmin edici geldi. \t 1\n",
            "yerli malı yurdun malı herkez bunu kullanmalı güzel telefon. \t 1\n",
            "Gerçek fiyatına ulaştığında alıcısı çok olacak bir ürün.. \t 1\n",
            "Eh işte.. \t 1\n",
            "Paket içeriğinde Lightning - 3,5 mm Kulaklık Jakı Adaptörü bulunmamakta. \t 1\n",
            "hesaplı oldugu sürece alışveriş yapacagım ürün başka yerde yok \t 1\n",
            "çok memnun kaldım 3 hafta sonra elime ulaştı. düzenli olarak kullandım çok işime yaradı:) \t 0\n",
            "ses kalitesi ii fakat ses yüksekliği yeterli değil parasına göre alinabilir bir ürün kullanışlı \t 1\n",
            "henüz kullanmadım ama uygun fiat ve iyi hizmet olduğunu düşünüyorum. \t 1\n",
            "kargo takibinde kısmi problemler yaşamama rağmen telefon fiyatına göre gayet tatmin edici \t 1\n",
            "Fakat adım saymada biraz hatası var. Ama uzun süre yürüyünce hata payı azalıyor. \t 1\n",
            "İlk geldiğinde cok güzel parlak tası vardı Zamanla parlaklığı kayboldu \t 0\n",
            "Küçük bir ürün. \t 0\n",
            "Çocuklar için ideal. \t 0\n",
            "urun fiyat olarak çok iyi ama kalite olarak çok ince \t 0\n",
            "ürün süper başka marketlerde bu fiyat yok \t 1\n",
            "M.L beden aldım XS beden gibi. \t 0\n",
            "yaklaşık 5 senedir kullanıyorum. defalarca düşmesine rağmen banamısın demedi. 5 yıl daha gider diye düşünüyorum. \t 1\n",
            "Kurulumu basit kendisi de işlevsel bir ürün \t 1\n",
            "Beklentimi karsiladi sarjida gayet iyi gidiyor karsi tarafa ses guzel gidip guzel geliyor tesekurler.... \t 1\n",
            "Ürünü kalitesi zaman içinde belli olur ama uygulaması ingilizce ve biraz karışık \t 1\n",
            "İyi gibi de şarjı çok yiyor \t 1\n",
            "Ürün güzel kargo kötü \t 1\n",
            "Beklediğimden çok daha sessiz çalışıyor. Soğutma performansı da yeterli i5'i süper soğutuyor. harika bir ürün \t 1\n",
            "Benim eski bilgisayarim şimdi yeni gibi \t 1\n",
            "değişim kolay. ekonomik sayılır. \t 1\n",
            "bilgisayar kullanacaklar için süper ürün ama telefondan bağlanamadım malesef bu üzücü \t 1\n",
            "27-03-2016 pazar akşamı siparişimi verdim 29- 03-2016 saat 16:00 da elime ulaştı .. \t 1\n",
            "ürün fena değil \t 1\n",
            "Ürün elime bugün ulaştı. Kullanmaya başladıktan sonra bilgisayarınız ilk günki gibi değil, daha iyi olacak. \t 1\n",
            "samsungtan hic beklenmeyen bir urun. asiri sesli calisiyor. \t 0\n",
            "Teşekkürler.Nedense pakete fatura konulmuyor! \t 1\n",
            "Çift taraflı bant kullanın daha iyi \t 0\n",
            "ürün fena değil diğer markalardan öyle çok bir farkı yok \t 0\n",
            "yazıcı gayet güzel ancak a5 boyutu basmıyor. alırken dikkat edilmeli a5 kullanılacaksa. \t 1\n",
            "Fena değil idare eder sipariş kuralları ve hızı çok iyi teşekkürler.. \t 0\n",
            "Muhteşem diyebilirim yalnız ben aldığımda fiyatı 25 liraydı 3 tane almıştım :D \t 1\n",
            "Ürün çabuk geldi çok şık bir görünüme sahip ama boyası ele çıkıyor geri sökmeyi düşünüyorum. \t 0\n",
            "Kamerasını begenmedim onun dışında fena değil \t 1\n",
            "Şarzı uzun süre gidiyor kullanışlı ve güzel bir zamandan sonra hep boynunuzda asılı sanıyorsunuz garip bir huy oluyor :D \t 1\n",
            "notebook restart zamanı 60 küsür saniyeden 10 saniyeye düştü. açma ve kapama 5er saniye. \t 1\n",
            "Orta kalitede faydalı bir ürün, android cihazınınız (OTG-etkin) destekleyip desteklemediğini kontrol etmelisiniz... \t 1\n",
            "ürün hakkında bir yorum belirtemeyecegim.sagolsun hepsiburada 1,5 ay da gönderemedi \t 0\n",
            "İçinden bilgisayara bağlama kablosu çıkmıyor ı yüzden 1 yıldız kestim. Garip ama art arda çekince yoruluyor. \t 1\n",
            "Daha ucuz olabilir en iyi fiyatları beklemekteyiz \t 0\n",
            "çok ince. \t 0\n",
            "idare eder \t 1\n",
            "not 3 tlfnum var birkere bile şarj edemeden kendi şarjı bitiyor \t 0\n",
            "Eko modu açık olmasa mikrofon un açık olduğunu anlamayacağım. Sesi çok az \t 0\n",
            "kargosu çok hızlı, hızlı şarj yapıyor fakat içinden çıkan kablosu çok kaliteli değil bide içinden adaptör çıkmıyor \t 1\n",
            "Ürün güzel ama kurulum denildiği kadar basit olmadı :D fiyata değer \t 1\n",
            "Oğluma aldım. 1 günde teslim edildi. Kaliteli güzel bir telefon ama kendime alacak olsam bu kadar para vermezdim. \t 1\n",
            "ürün 2 gun icinde geldi ulastırma ii ürünü daha kullanmadım \t 1\n",
            "Iyi has ama ucuz degil kablosu farkli ve kisa piyasada zor bulunur \t 1\n",
            "Yeni aldık kullanıyoruz pişman olmadık Güzel ürün \t 1\n",
            "kulağı terletmesi ve mikrofonun sesi boğuk vermesi dışında diğer özelleri iyi. \t 0\n",
            "çOK GÜZEL BİR ŞEY DEĞİL. Ancak hızlı gönderi mükemmel. \t 0\n",
            "abartıldığı kadar olmasada güzel bir ürün \t 0\n",
            "Sar değeri çok fazla olunca vazgeçtim. Sağlıktan önemlisi yok. \t 0\n",
            "ürün gündüz gece ayrimi yapmaksizin hareket halinde yaniyor \t 0\n",
            "Yanında birde klonloma proğramı verseler.. \t 1\n",
            "Kalite denince akla gelen hepsi burada.com.. Arayıpta yokmuş dediğim hiç birşey olmadı. Teşekkürler \t 1\n",
            "Tekerlekler slikon olmadıgından hem ses yapiyor hemde rahat ve hızlı bir sürüş mümkün degil.... \t 0\n",
            "hız olarak 10mb\\s yazma 48mb\\s okuma. orta seviye akıllı telefonlar için uygundur. \t 1\n",
            "Dehşetül-Vahşet bir ürün \t 0\n",
            "Bir oyuncuya göre ağır.Ama sizin için sorun olmazsa.Bana sorun olmaz ama sizi bilmem \t 1\n",
            "fiyat ve teslimatı mükemmel teşekkürler \t 0\n",
            "makine fantomdu f35 oldu o derece \t 1\n",
            "Super hızlı 5 günde gelir ?????????????? \t 0\n",
            "Aldım ürünü sorunsuz bir şekilde teslim aldım \t 1\n",
            "2011 yılında buradan almıştım .Hâlâ sapasağlam. Görüntüsü de hiç bozulmadı. \t 1\n",
            "Dolar çıktı Hepsi düşürdü. Yurt dışı garantisiz, Hepsi orijinal :) \t 1\n",
            "Düşündüğüm kadar güzül değil beğenmediğim yönleri varrrrrrrr daha iyi olabilir diiiiiiiii \t 0\n",
            "ürün piyasaya göre fiat olarak biraz yüksek ama taksitli olması güzel:) \t 0\n",
            "Kartuş fiyatına yazıcı. Az kullanımlar için yeterli bir yazıcı, sadece işlemcisi düşük eski bilgisayarda çalışmıyor. \t 1\n",
            "Urun çok kalın ve taşınması zor. Değişim ile ilgili yardımlarınızı rica ederim. \t 0\n",
            "alacak olan arkadaşlara tavsıyem kalem pıl ıle çalışıyor bılgınız olsun \t 0\n",
            "Fıkır olarak güzel ama urunun kalitesi iyi değil kılıfı, içindeki boruları, Kaliteli olan markaları tercih edin \t 0\n",
            "1 dakikada zor açılan laptop 16 saniyede aciliyor 2009 model laptobu ayağa kaldırdı. \t 1\n",
            "fiyata göre fena değil \t 0\n",
            "Ürün iyi fakat Teknoraks şirketinin ürünü göndermesi 5 gün sürdü. Satıcısı Hepsiburada olanlar 1 gün de geliyor. \t 1\n",
            "aldığım oyunda Türkçe dil seçeneği yok. Türkçe altyazı yok \t 0\n",
            "ürün iyi ama doğru ürünü göndermeleri biraz zaman aldı??? \t 0\n",
            "Eğer Fiyatı 5 tl olsaydı harika bir ürün diyebilirdim... \t 0\n",
            "Güzel ürün kullanışlı ağır değil \t 1\n",
            "Ürünü günümüz akıllı telefonların çağrı cihazı olarak düşünebilirsiniz fakat ios için programının geliştirilmesi gerek \t 1\n",
            "kullanmak için dikkat ve zaman lazım. yorucu bir alet. biraz daha rahat kullanımlı birşeyler iyi olurdu. \t 0\n",
            "kaliteli değil.. iş görürmü .. görür .. fazla bişey beklememk gerek \t 0\n",
            "Aradım aradım gerçekten daha ucuzu yok. Bulamadım. Kalitesi hakkında bir fikrim yok. Alınca göreceğiz. Hayırlısı... \t 1\n",
            "prizden kolayca kablo ile birlikte çıkıyor \t 0\n",
            "Mıknatıs güçlü her telefona uyumlu \t 1\n",
            "23/11/17 SAAT 23:00'DA VERDİĞİM SİPARİŞİM 24/11/17 SAAT 13:00'DA TESLİM EDİLDİ. \t 1\n",
            "fiyatına göre bir ürün \t 0\n",
            "WiFi çekim gücü yeterli değil, fiyatını baz alırsak normal \t 1\n",
            "Fena degil fiyatına göre uygun bir ürün \t 0\n",
            "PLASTİK VE YER KAPLAYAN ŞEYLERİ SEVİYORSANIZ SATIN ALMAK İÇİN ACELE EDİN \t 0\n",
            "genaral mobile android one 4g ye uyumlumu daha once baska marka aldim ama uuymadi \t 1\n",
            "USB 2.0 dan geçiş yaptım ve şuan ürün bana çok hızlı geliyor. Fakat ilerde bu da yavaş kalacak \t 1\n",
            "fiyatı çok uygun. eski laptopıma taktım ciddi bir hız artışı var \t 1\n",
            "wifi şebekesi beklediğim gibi ortalama 50 60 mt rahat çekiyor sonrası pert :) \t 1\n",
            "Biraz yumusak icim \t 0\n",
            "keşke yürürken de nabız ölçebilseydi \t 1\n",
            "Ürün malzeme kalitesi çokiyi fakat ses konusunda çokta tatmin edici bulmadım. \t 1\n",
            ".kullanmaya basladım henüz bir etkisi yok.ama bakalım belki daha sonra görülür etkisi.teşekkürler. \t 0\n",
            "Görüldüğü gibi değil. Gıcır gıcır ses çıkarıyor. \t 0\n",
            "Fena değil, 5 üzerinde 2,5 puan yeterli. Üstün kalite beklemeyen ancak ihtiyacını karşılamak isteyenler satın alabilir. \t 0\n",
            "Ürünün hızı tam da istediğim gibi değil. İdare eder bu fiyata.. \t 0\n",
            "Bu üründe harici sd kart girişi yok yalnız... Hepsiburadanın bu kısmı gözden geçirmesi gerek... \t 1\n",
            "süper hızlı gönderim denilen ürün 5 günde elime ulaştı teşekkürler. \t 0\n",
            "Sanki biraz küçük, hafif ve çok zıplıyor. Kargo hızlı geldi. Plastik top hissiyatı verdiği iddiasına katıyorum. \t 0\n",
            "Daha önce kodak kullandım Ürün 1 günde hızlı geldi, çok ince geldi bana Tab edince karar vercem \t 0\n",
            "Baskı kalitesi iyi değil ama iş görür \t 0\n",
            "Orijinal ürün ne diyebilirim ki zaten bu sitenin kargo problemi yok onu da herkes biliyor \t 1\n",
            "Görselde beyaz gözüküyor bana gri renk geldi ve üzerinde ön tarafında çizik gibi 2 ad. iz var. \t 0\n",
            "Çok çabuk ısınıyor ?????? \t 0\n",
            "Hızlı kargoyla geldi. Laptop yavaşlığı için kesin çözüm arkadaşlar... \t 1\n",
            "Gözü çok ağrıtıyor ama güzel ürün \t 0\n",
            "Menü pratik değil ve anlaşılması güç bir telefon. Ancak hizmetiniz mükemmel. Teşekkür ederim. \t 0\n",
            "ürünün şarj tarzı uygun deyil.dönüştürücü gerek.dönüştürücüyle birlikte fiyat artıyor. \t 0\n",
            "Iphone için app bulunmuyor. Ama olsun hiç önemli değil. Önemli olan Batuhan' ın mutlu olmasıydı ve oldu. \t 0\n",
            "Hersey dogru! \t 1\n",
            "Fena değil bu paraya iyi \t 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTiNoIjLJKxC"
      },
      "source": [
        "examples = [\n",
        "            \":)\",\n",
        "            \":))\",\n",
        "            \"😚\",\n",
        "            \"turkcell :)\",\n",
        "            \"seni seviyorum turkcell\",\n",
        "            \"gayet güzel\",\n",
        "            \"güzel\",\n",
        "            \"çok güzel\",\n",
        "            \"çok iyi\",\n",
        "            \"gayet güzel\",\n",
        "            \"güzeldi\",\n",
        "            \"güzelmiş\",\n",
        "            \"çok güzeldi\",\n",
        "            \"çok güzelmiş\",\n",
        "            \"beğendim\",\n",
        "            \"beğendik\",\n",
        "            \"beğendi\",\n",
        "            \"çok beğendim\",\n",
        "            \"çok beğendik\",\n",
        "            \"çok beğendik!!!\",\n",
        "            \"sevdim\",\n",
        "            \"sevdik\",\n",
        "            \"çok sevdim\",\n",
        "            \"hiç kötü değil\",\n",
        "            \"kötü değil\",\n",
        "            \"kötü değildi\",\n",
        "            \"kötü değilmiş\",\n",
        "            \"turkcell candır\",\n",
        "            \"turkcell candir\",\n",
        "            \":(\",\n",
        "            \":((\",\n",
        "            \"🙁\",\n",
        "            \"turkcell berbat\",\n",
        "            \"turkcell rezilsin\",\n",
        "            \"rezilsin turkcell\",\n",
        "            \"turkcell 🙁\",\n",
        "            \"rezillik\",\n",
        "            \"berbat\",\n",
        "            \"berbattı\",\n",
        "            \"rezildi\",\n",
        "            \"paramızla rezil olduk\",\n",
        "            \"kötü\",\n",
        "            \"çok kötü\",\n",
        "            \"çok kötü!!!!\",\n",
        "            \"kötüydü\",\n",
        "            \"çok kötüydü\",\n",
        "            \"güzel değil\",\n",
        "            \"güzel değildi\",\n",
        "            \"iyi değil\",\n",
        "            \"iyi değildi\",\n",
        "            \"hiç güzel değil\",\n",
        "            \"hiç güzel değildi\",\n",
        "            \"pek güzel değildi\",\n",
        "            \"pek güzel sayılmaz\",\n",
        "            \"pek de güzel sayılmaz\",\n",
        "            \"begenmedim\",\n",
        "            \"beğenmedim\",\n",
        "            \"pek beğenmedim\",\n",
        "            \"hiç beğenmedim\",\n",
        "            \"sevmedim\",\n",
        "            \"sevemedim\", \n",
        "            \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO4SKvY1IXR1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1266e48-4888-44cf-c57a-18834d60df29"
      },
      "source": [
        "for ex in examples:\n",
        "    tt = tok.texts_to_sequences([preprocess(ex)])\n",
        "    ptt = pad_sequences(tt, MAX_LEN, padding=\"post\")\n",
        "    pred = model.predict(ptt)\n",
        "    print(ex)\n",
        "    print(np.round(pred[0]).astype(int))\n",
        "    print(\"---------------\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":)\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            ":))\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "😚\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell :)\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "seni seviyorum turkcell\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "gayet güzel\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "güzel\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok güzel\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok iyi\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "gayet güzel\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "güzeldi\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "güzelmiş\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok güzeldi\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok güzelmiş\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "beğendim\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "beğendik\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "beğendi\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok beğendim\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok beğendik\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok beğendik!!!\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "sevdim\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "sevdik\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok sevdim\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "hiç kötü değil\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "kötü değil\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "kötü değildi\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "kötü değilmiş\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell candır\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell candir\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            ":(\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            ":((\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "🙁\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell berbat\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell rezilsin\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "rezilsin turkcell\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell 🙁\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "rezillik\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "berbat\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "berbattı\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "rezildi\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "paramızla rezil olduk\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "kötü\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok kötü\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok kötü!!!!\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "kötüydü\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "çok kötüydü\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "güzel değil\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "güzel değildi\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "iyi değil\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "iyi değildi\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "hiç güzel değil\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "hiç güzel değildi\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "pek güzel değildi\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "pek güzel sayılmaz\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "pek de güzel sayılmaz\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "begenmedim\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "beğenmedim\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "pek beğenmedim\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "hiç beğenmedim\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "sevmedim\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "sevemedim\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpaC0t9667fC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g43lxLQq675l"
      },
      "source": [
        "model.save(\"sentiment_model.hd5\")\n",
        "\n",
        "import json, codecs\n",
        "\n",
        "tokenizer_json = tok.to_json()\n",
        "with codecs.open('sentiment_tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaPX6JyS_YVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}