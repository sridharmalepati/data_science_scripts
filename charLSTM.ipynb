{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "charLSTM",
      "provenance": [],
      "authorship_tag": "ABX9TyOQk7g5TcsP3UOM+edeA3nD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuyguA/data_science_scripts/blob/master/charLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpzphVmLPWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9bdc35a-ff12-4501-d453-fdbce2e522f3"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Dense, Bidirectional, BatchNormalization, Dropout, Input, Embedding, GlobalMaxPool1D, MaxPooling1D, SpatialDropout1D, Conv1D\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjo-N_MILXMN"
      },
      "source": [
        "sentences = []\n",
        "y = []\n",
        "\n",
        "with open(\"all_sentiment_train.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        example =  \" \".join(s.strip().split())\n",
        "        sentences.append(example)\n",
        "        y.append(int(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86QVcyTKLfM0"
      },
      "source": [
        "tokenizer = Tokenizer(\n",
        "    char_level=True,\n",
        "    filters=None,\n",
        "    lower=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fe_KDKOLh5e"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "809nMX59LjF9"
      },
      "source": [
        "MAX_LEN = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDj4KrNCLnpV"
      },
      "source": [
        "X_char = pad_sequences(sequences, MAX_LEN, padding=\"post\")\n",
        "X_char = np.array(X_char)\n",
        "y = np.array(y)\n",
        "embed_size = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICCOsIl5Ls0o"
      },
      "source": [
        "inp = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(input_dim = len(tokenizer.word_index)+1, output_dim = embed_size, input_length=MAX_LEN, mask_zero=True)(inp)\n",
        "sdrop = SpatialDropout1D(0.2)(x)\n",
        "h = Bidirectional(LSTM(units=100, return_sequences=False, recurrent_dropout=0.2, dropout=0.2))(sdrop)\n",
        "output = Dense(1, activation='sigmoid')(h)\n",
        "model = Model(inputs=inp, outputs=output)\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXxp-VTnL0vB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "cdf29510-f503-486f-d09b-bcd22940916d"
      },
      "source": [
        "model.fit(X_char,y, batch_size=256, epochs=10,validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 41256 samples, validate on 4585 samples\n",
            "Epoch 1/10\n",
            "41256/41256 [==============================] - 2620s 64ms/step - loss: 0.6400 - accuracy: 0.6323 - val_loss: 0.6061 - val_accuracy: 0.6711\n",
            "Epoch 2/10\n",
            "41256/41256 [==============================] - 2599s 63ms/step - loss: 0.5973 - accuracy: 0.6823 - val_loss: 0.5784 - val_accuracy: 0.6995\n",
            "Epoch 3/10\n",
            "41256/41256 [==============================] - 2619s 63ms/step - loss: 0.5790 - accuracy: 0.6993 - val_loss: 0.5579 - val_accuracy: 0.7117\n",
            "Epoch 4/10\n",
            "41256/41256 [==============================] - 2620s 64ms/step - loss: 0.5608 - accuracy: 0.7103 - val_loss: 0.5482 - val_accuracy: 0.7202\n",
            "Epoch 5/10\n",
            "41256/41256 [==============================] - 2604s 63ms/step - loss: 0.5528 - accuracy: 0.7166 - val_loss: 0.5371 - val_accuracy: 0.7293\n",
            "Epoch 6/10\n",
            "41256/41256 [==============================] - 2614s 63ms/step - loss: 0.5347 - accuracy: 0.7326 - val_loss: 0.5202 - val_accuracy: 0.7391\n",
            "Epoch 7/10\n",
            "41256/41256 [==============================] - 2590s 63ms/step - loss: 0.5290 - accuracy: 0.7333 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
            "Epoch 8/10\n",
            "41256/41256 [==============================] - 2601s 63ms/step - loss: 0.5128 - accuracy: 0.7455 - val_loss: 0.5758 - val_accuracy: 0.6833\n",
            "Epoch 9/10\n",
            "41256/41256 [==============================] - 2624s 64ms/step - loss: 0.5191 - accuracy: 0.7396 - val_loss: 0.4996 - val_accuracy: 0.7514\n",
            "Epoch 10/10\n",
            " 4352/41256 [==>...........................] - ETA: 37:58 - loss: 0.5097 - accuracy: 0.7468"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}