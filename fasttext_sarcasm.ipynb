{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext sarcasm",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNYsM1zwo0MaBxZ/HyCN5s8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuyguA/data_science_scripts/blob/master/fasttext_sarcasm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sXqx9ZC4JO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "4645e079-4e36-4ccc-f543-3f3fbe461cb0"
      },
      "source": [
        "!!pip3 install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting fasttext',\n",
              " '\\x1b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)',\n",
              " '',\n",
              " '\\x1b[K     |████▊                           | 10kB 22.0MB/s eta 0:00:01',\n",
              " '\\x1b[K     |█████████▌                      | 20kB 6.7MB/s eta 0:00:01',\n",
              " '\\x1b[K     |██████████████▎                 | 30kB 7.2MB/s eta 0:00:01',\n",
              " '\\x1b[K     |███████████████████             | 40kB 8.7MB/s eta 0:00:01',\n",
              " '\\x1b[K     |███████████████████████▉        | 51kB 7.5MB/s eta 0:00:01',\n",
              " '\\x1b[K     |████████████████████████████▋   | 61kB 8.4MB/s eta 0:00:01',\n",
              " '\\x1b[K     |████████████████████████████████| 71kB 4.8MB/s ',\n",
              " '\\x1b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)',\n",
              " 'Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.3)',\n",
              " 'Building wheels for collected packages: fasttext',\n",
              " '  Building wheel for fasttext (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3016287 sha256=2ac774d5d0ac724b5b2d647453abda2e83188742eb3b4c82e48a40308fd8fa5a',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592',\n",
              " 'Successfully built fasttext',\n",
              " 'Installing collected packages: fasttext',\n",
              " 'Successfully installed fasttext-0.9.2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzobhMIbDCel"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlOrTTPNDOJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b95f5c92-8a9e-4185-988d-a1c40d6a4210"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-01 10:54:32--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4506977940 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.tr.300.bin.gz’\n",
            "\n",
            "cc.tr.300.bin.gz    100%[===================>]   4.20G  11.0MB/s    in 6m 37s  \n",
            "\n",
            "2020-05-01 11:01:10 (10.8 MB/s) - ‘cc.tr.300.bin.gz’ saved [4506977940/4506977940]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNN_hKGkDavB"
      },
      "source": [
        "!gzip -d cc.tr.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ynYKIM2DbIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb9e196f-57f2-4029-8515-47f01972d172"
      },
      "source": [
        "m = fasttext.load_model(\"cc.tr.300.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXbX2sPCDbZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9509d68-88af-42f1-bd75-c30f55181b3b"
      },
      "source": [
        "dir(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_labels',\n",
              " '_words',\n",
              " 'f',\n",
              " 'get_analogies',\n",
              " 'get_dimension',\n",
              " 'get_input_matrix',\n",
              " 'get_input_vector',\n",
              " 'get_label_id',\n",
              " 'get_labels',\n",
              " 'get_line',\n",
              " 'get_meter',\n",
              " 'get_nearest_neighbors',\n",
              " 'get_output_matrix',\n",
              " 'get_sentence_vector',\n",
              " 'get_subword_id',\n",
              " 'get_subwords',\n",
              " 'get_word_id',\n",
              " 'get_word_vector',\n",
              " 'get_words',\n",
              " 'is_quantized',\n",
              " 'labels',\n",
              " 'predict',\n",
              " 'quantize',\n",
              " 'save_model',\n",
              " 'set_args',\n",
              " 'set_matrices',\n",
              " 'test',\n",
              " 'test_label',\n",
              " 'words']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEm98caKDbpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4660d90-496c-4efb-a8cb-b40e30b9052e"
      },
      "source": [
        "len(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7509"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7B3xFoQrwyg"
      },
      "source": [
        "import re\n",
        "\n",
        "#from emoticon_smiley import replace_smileys\n",
        "\n",
        "opponents = [\"bimcell\", \"pttcell\", \"ttnet\", \"vodafone\", \"avea\", \"netcell\", \"vestelcell\", \"turk telekom\", \"turktelekom\", \"turknet\"]\n",
        "opp_regex = r\"@?(\" + r\"|\".join(opponents) + r\")(\\w+)?\"\n",
        "\n",
        "def replace_ceo(sentence):\n",
        "  sentence = re.sub(r\"(@?Kaan_?Terzio[gğ]lu|\\bkaan\\b)\", \"CEO\", sentence, flags=re.I)\n",
        "  return sentence\n",
        "\n",
        "def replace_opponents(sentence):\n",
        "  sentence = re.sub(opp_regex, \" rakip şirket \", sentence, flags=re.I)\n",
        "  return sentence\n",
        "\n",
        "def replace_self_mentions(sentence):\n",
        "  sentence = re.sub(\"t.?rkcll?\", \"turkcell\", sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_entities(sentence):\n",
        "  sentence = replace_ceo(sentence)\n",
        "  sentence = replace_opponents(sentence)\n",
        "  #sentence = replace_self_mentions(sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_dots(sentence):\n",
        "  sentence = sentence.replace(u\"\\u2026\", \"...\").replace(u\"\\u2025\", \"..\").replace(u\"\\u1427\", \".\")\n",
        "  return sentence\n",
        "\n",
        "def replace_brackets(sentence):\n",
        "  sentence = sentence.replace(\"}\", \" \").replace(\"{\", \" \").replace(\"]\", \" \").replace(\"[\", \" \")\n",
        "  return sentence\n",
        "\n",
        "def replace_quotation_marks(sentence):\n",
        "  rlist = [ u\"\\u2018\", u\"\\u201c\", u\"\\u201d\", '\"', u\"\\u0060\", u\"\\u00b4\", u\"\\u2019\"]\n",
        "  for r in rlist:\n",
        "    sentence = sentence.replace(r, \" \")\n",
        "  return sentence\n",
        "\n",
        "def replace_url(sentence):\n",
        "  url_string = r\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\"\n",
        "  return re.sub(url_string, \" websitesi \", sentence)\n",
        "\n",
        "def replace_underscore(sentence):\n",
        "  sentence = re.sub(r\"(?<=\\s)_(?=\\s)\", \" \", sentence)\n",
        "  sentence = re.sub(r\"(?<=\\w)([,:;])\", r\" \\1\", sentence)\n",
        "  sentence = re.sub(r\"(?<=[\\w\\s])([|<>/-])(?=[\\w\\s])\" , \" \", sentence)\n",
        "  return sentence\n",
        "\n",
        "def process_quotation(sentence):\n",
        "  sentence = re.sub(r\"(?<![.\\d])\\.\", \" .\", sentence)\n",
        "  sentence = re.sub(r\"\\.(?![.\\d])\", \". \", sentence)\n",
        "  sentence = sentence.replace(\"?\", \" ? \").replace(\"!\", \" ! \")\n",
        "  sentence = re.sub(r\"[\\s#\\@]\", \" \", sentence)\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def preprocess(sentence):\n",
        "  sentence = sentence.strip()\n",
        "  sentence = sentence.lower()\n",
        "  sentence = replace_url(sentence)\n",
        "  sentence = replace_entities(sentence)\n",
        "  sentence = replace_dots(sentence)\n",
        "  sentence = replace_brackets(sentence)\n",
        "  sentence = replace_quotation_marks(sentence)\n",
        "  sentence = replace_underscore(sentence)\n",
        "  sentence = process_quotation(sentence)\n",
        "  tokens = sentence.strip().split()\n",
        "  #t = replace_smileys(tokens)\n",
        "  return  tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyi7XqSXsbc1"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxRcCjH6sbvA",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "860eb304-c539-4690-b508-1d744c85a4be"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed4041c0-7ead-4892-ba7a-a4a07d25fd9a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ed4041c0-7ead-4892-ba7a-a4a07d25fd9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving all_train.csv to all_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0sc7dmQscCz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZneeHtncUa"
      },
      "source": [
        "sentences = []\n",
        "y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5rK794ki4W0"
      },
      "source": [
        "with open(\"sarcasm_train.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        sentences.append(s)\n",
        "        y.append(int(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK77usaFKeco"
      },
      "source": [
        "test_sentences = []\n",
        "test_y = []\n",
        "\n",
        "with open(\"test_sarcasm.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        l = line.strip()\n",
        "        s, res = l.rsplit(\"\\t\", 1)\n",
        "        test_sentences.append(s)\n",
        "        test_y.append(int(res))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCQaVHn9s-8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9388c9c3-1fbd-489b-a008-20f80bd9fb71"
      },
      "source": [
        "words = set()\n",
        "for sentence in sequences:\n",
        "    for word in sentence:\n",
        "        words.add(word)\n",
        "\n",
        "for sentence in test_seqs:\n",
        "  for word in sentence:\n",
        "    words.add(word)\n",
        "\n",
        "n_words = len(words)\n",
        "print(n_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbeg-BB_4PwA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dARL26YSoZDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2b0acc8-3551-48ce-a526-f89197a300fb"
      },
      "source": [
        "sequences[1188]\n",
        "#sentences[1188]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hmzamrsl', 'medallion', 'ama', 'en', 'iyisi', 'turkcell', '01', '01']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIvDF6fcrxW-"
      },
      "source": [
        "sequences = [preprocess(sentence) for sentence in sentences]\n",
        "test_seqs = [preprocess(t_sentence) for t_sentence in test_sentences]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr1c49tlGyu2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc0cJMg6tvc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a439707-56a5-4f76-e975-2f3f64cd8453"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbKDaWOuuMb"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOatna3ZuugK"
      },
      "source": [
        "tok = Tokenizer(n_words+1, lower=True)\n",
        "tok.fit_on_texts(sequences+ test_seqs )\n",
        "X_word = tok.texts_to_sequences(sequences)\n",
        "X_word = pad_sequences(X_word, maxlen=MAX_LEN, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrbFZ_tM4Bwp"
      },
      "source": [
        "test_sequences = tok.texts_to_sequences(test_seqs)\n",
        "X_test = pad_sequences(test_sequences, MAX_LEN, padding=\"post\")\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "test_y = np.array(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iYqbydGtoh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fva_c95vv7TM"
      },
      "source": [
        "MAX_LEN =60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkFLUb_9wAfZ"
      },
      "source": [
        "word_index = tok.word_index\n",
        "embed_size=300\n",
        "embedding_matrix = np.zeros((n_words+1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= n_words: continue\n",
        "    embedding_vector = m.get_word_vector(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIoRIdyMxZcp"
      },
      "source": [
        "X_word = np.array(X_word)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtHjH6439BdF"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(100, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=word_in, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB82A27u9IA6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3mKMDnO9IR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "06e5b72d-06c3-4997-df69-ffacfe914631"
      },
      "source": [
        "history = model.fit(X_word, y, batch_size=32, epochs=5,  verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16910/16910 [==============================] - 100s 6ms/step - loss: 0.1004 - accuracy: 0.9672\n",
            "Epoch 2/5\n",
            "16910/16910 [==============================] - 99s 6ms/step - loss: 0.0089 - accuracy: 0.9975\n",
            "Epoch 3/5\n",
            "16910/16910 [==============================] - 100s 6ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 4/5\n",
            "16910/16910 [==============================] - 99s 6ms/step - loss: 2.5855e-04 - accuracy: 0.9999\n",
            "Epoch 5/5\n",
            "16910/16910 [==============================] - 99s 6ms/step - loss: 7.0216e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uEO0i29RGf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e84a057-e743-4330-b76a-3c47ab7e572d"
      },
      "source": [
        "results = model.evaluate(X_test, test_y, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 1s 835us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HVuCFgBN20O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "899a0fb3-48d4-40d1-c254-d44bcc516051"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05419917544437594, 0.9866071343421936]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVm9k_IrwDdG"
      },
      "source": [
        "incorrects = np.nonzero(np.round(model.predict(X_test).reshape((-1,))).astype(int) != test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpOMeEnYBQ7Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31eb8325-6d36-4676-92b3-fdec252a20bf"
      },
      "source": [
        "len(incorrects[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH1251wqyi4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f719ca55-8bcb-4846-97e1-9d152e653ccc"
      },
      "source": [
        "for i in incorrects[0]:\n",
        "  print(test_sentences[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "turkcel beni bu sefer hangi kampanyayla aldatıcaksın?\n",
            "turkcell kaplumbağa hızında hizmet veriyor\n",
            "leylayı bekleyen mecnun olduk ama hala gelmediniz\n",
            "internetimde çok hızlı donmadan edemiyor\n",
            "her gün mü geri aranır ne bu sevda sizdeki\n",
            "gönüllerin birincisi değil küfürlerin birincisisiniz\n",
            "güzel güzel reklamlar verene kadar güzel güzel işlerinizi rayına soksaydınız daha iyiydi\n",
            "size müşteri olarak hayatımın hatasını yapmışım\n",
            "saygısızlık yapmakta daha iyisi yook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbHMdcRWuSTB"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Ge8TKs1EPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2db38e3-274f-46d1-dfb3-d1c838955287"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "weight_decay = 1e-4\n",
        "num_filters=64\n",
        "\n",
        "word_in = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "conv = Conv1D(num_filters, 7, activation='relu', padding='same')(x)\n",
        "mp1 = MaxPooling1D(2)(conv)\n",
        "conv1 = Conv1D(num_filters, 7, activation='relu', padding='same')(mp1)\n",
        "mp2 = GlobalMaxPooling1D()(conv1)\n",
        "dp1 = Dropout(0.5)(mp2)\n",
        "dense1  = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(dp1)\n",
        "dense2 = Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model = Model(input=word_in, outputs=dense2)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UFJi89o1Lgn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "465e5209-adfb-4d4a-92d5-1f7c5d91f6e3"
      },
      "source": [
        "model.fit(X_word,y, batch_size=32, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16910/16910 [==============================] - 53s 3ms/step - loss: 0.1305 - accuracy: 0.9488\n",
            "Epoch 2/10\n",
            "16910/16910 [==============================] - 52s 3ms/step - loss: 0.0209 - accuracy: 0.9951\n",
            "Epoch 3/10\n",
            "16910/16910 [==============================] - 52s 3ms/step - loss: 0.0064 - accuracy: 0.9988\n",
            "Epoch 4/10\n",
            "16910/16910 [==============================] - 52s 3ms/step - loss: 0.0045 - accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "16910/16910 [==============================] - 51s 3ms/step - loss: 0.0031 - accuracy: 0.9996\n",
            "Epoch 6/10\n",
            "16910/16910 [==============================] - 51s 3ms/step - loss: 0.0027 - accuracy: 0.9995\n",
            "Epoch 7/10\n",
            "16910/16910 [==============================] - 51s 3ms/step - loss: 0.0035 - accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "16910/16910 [==============================] - 51s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "16910/16910 [==============================] - 51s 3ms/step - loss: 9.4959e-04 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "16910/16910 [==============================] - 51s 3ms/step - loss: 7.2794e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa097224be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW5nqDiXWCR4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52feddb5-eec9-4044-9f7c-98203565654c"
      },
      "source": [
        "results = model.evaluate(X_test, test_y, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 0s 224us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFARbqmzagZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1082db5-0cfb-47fb-a445-ff9ed742c415"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18152425550146117, 0.9717261791229248]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AW5B2043rPS"
      },
      "source": [
        "incorrects = np.nonzero(np.round(model.predict(X_test).reshape((-1,))).astype(int) != test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Papg1RPG3vC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5103a576-43f9-48f7-a266-a49a265175b4"
      },
      "source": [
        "len(incorrects[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlRW2WV3w5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "7ad5bd88-04f4-4634-f644-0e45961544e7"
      },
      "source": [
        "for i in incorrects[0]:\n",
        "  print(test_sentences[i], \"\\t\", test_y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "turkcel beni bu sefer hangi kampanyayla aldatıcaksın? \t 1\n",
            "turkcell kaplumbağa hızında hizmet veriyor \t 1\n",
            "telefon faturam bana mı özel yoksa bir kaç kişinin faturasını da mı ben ödüyorum \t 1\n",
            "internetimde çok hızlı donmadan edemiyor \t 1\n",
            "senden operatör saglayıcısı olmaz sadece dert saglayıcı olur \t 1\n",
            "bu nasıl telefon borcu sanki yeni hat numarası gibi \t 1\n",
            "evimin toplam gideri telefon faturamdan az geliyor bu ne saçmalık \t 1\n",
            "şebeke sorunuyla neden bir tek ben ugraşıyorum \t 1\n",
            "her gün mü geri aranır ne bu sevda sizdeki \t 1\n",
            "gönüllerin birincisi değil küfürlerin birincisisiniz \t 1\n",
            "bu faturaya göre benim zengin olmam lazım \t 1\n",
            "turkcell ve yine usulsüzlük \t 1\n",
            "modem kurma işini on gündür yapamadılar soran olursa köprü yaptılar \t 1\n",
            "turkcel dediler geçelim dedik o bize geçirdi \t 1\n",
            "bıktım artık bu sizin şirketinizin gizli kapaklı oyunlarından \t 1\n",
            "TurkNet'in Çözümsüz Müşteri Hizmetleri! \t 1\n",
            "güzel güzel reklamlar verene kadar güzel güzel işlerinizi rayına soksaydınız daha iyiydi \t 1\n",
            "size müşteri olarak hayatımın hatasını yapmışım \t 1\n",
            "benim babam da milyarder zaten bu fatura hiç sorun olmaz \t 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZa8Mt65HQTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c76b89e-76ee-4015-a6ef-824d7fa3d8d3"
      },
      "source": [
        "results2 = model.evaluate(X_sc_test, test_sixclass_y, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 0s 250us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5LYyjuFHVjo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "796ba856-b0c3-456a-e384-de2640028123"
      },
      "source": [
        "results2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012542072430253029, 0.9919999837875366]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTiNoIjLJKxC"
      },
      "source": [
        "examples = [\n",
        "            \":)\",\n",
        "            \":))\",\n",
        "            \"😚\",\n",
        "            \"turkcell :)\",\n",
        "            \"seni seviyorum turkcell\",\n",
        "            \"turkcell her yerde cekiyor\",\n",
        "            \"turkcell her yerde çekiyor\",\n",
        "            \"turkcell candır\",\n",
        "            \"turkcell candir\",\n",
        "            \"🙁\",\n",
        "            \"turkcell berbat\",\n",
        "            \"turkcell rezilsin\",\n",
        "            \"rezilsin turkcell\",\n",
        "            \"turkcell 🙁\",\n",
        "            \"fizandan geliyor herhalde\",\n",
        "            \"faturam fizandan gelicek herhalde\",\n",
        "            \"harika müsteri hizmetleri için teşekkür ederim günümü berbat ettiniz\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO4SKvY1IXR1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1eaffae-e2f3-4e5e-9b27-629b7cb424cb"
      },
      "source": [
        "for ex in examples:\n",
        "    tt = tok.texts_to_sequences([preprocess(ex)])\n",
        "    ptt = pad_sequences(tt, MAX_LEN, padding=\"post\")\n",
        "    pred = model.predict(ptt)\n",
        "    print(ex)\n",
        "    print(np.round(pred[0]).astype(int))\n",
        "    print(\"---------------\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":)\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            ":))\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "😚\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell :)\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "seni seviyorum turkcell\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell her yerde cekiyor\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell her yerde çekiyor\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell candır\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell candir\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "🙁\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell berbat\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell rezilsin\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "rezilsin turkcell\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "turkcell 🙁\n",
            "[0]\n",
            "---------------\n",
            "\n",
            "\n",
            "fizandan geliyor herhalde\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "faturam fizandan gelicek herhalde\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n",
            "harika müsteri hizmetleri için teşekkür ederim günümü berbat ettiniz\n",
            "[1]\n",
            "---------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNr6Wve-681O"
      },
      "source": [
        "### diger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpaC0t9667fC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g43lxLQq675l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPfYMegjzt3T"
      },
      "source": [
        "from keras.layers import SpatialDropout1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaPX6JyS_YVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwCHqSjQ_Y4S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "3c7028c4-36e0-4cb0-d47d-924e5cb91d04"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "x = SpatialDropout1D(0.3)(emb_word)\n",
        "main_lstm = Bidirectional(LSTM(units=50, return_sequences=False,\n",
        "                               recurrent_dropout=0.3))(x)\n",
        "out = Dense(1, activation=\"sigmoid\")(main_lstm)\n",
        "\n",
        "model = Model(inputs=word_in, outputs=out)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_word, y,  batch_size=32, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20192/20192 [==============================] - 114s 6ms/step - loss: 0.3529 - accuracy: 0.8439\n",
            "Epoch 2/5\n",
            "20192/20192 [==============================] - 113s 6ms/step - loss: 0.0621 - accuracy: 0.9780\n",
            "Epoch 3/5\n",
            "20192/20192 [==============================] - 113s 6ms/step - loss: 0.0152 - accuracy: 0.9955\n",
            "Epoch 4/5\n",
            "20192/20192 [==============================] - 112s 6ms/step - loss: 0.0094 - accuracy: 0.9969\n",
            "Epoch 5/5\n",
            "20192/20192 [==============================] - 111s 6ms/step - loss: 0.0053 - accuracy: 0.9980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYFo3sMbaoAT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7304159f-dd6f-42e7-eeed-c345f65e8095"
      },
      "source": [
        "results = model.evaluate(X_test, test_y, batch_size=32)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 0s 704us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1021079950332642, 0.8140000104904175]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R77VlV57_Fb9"
      },
      "source": [
        "### Diger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTqKRh5WDYzm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "0c5cf317-b23e-46d6-adac-82557bd8e0ce"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "\n",
        "main_lstm = Bidirectional(LSTM(units=50, return_sequences=False,\n",
        "                               recurrent_dropout=0.3))(emb_word)\n",
        "out = Dense(1, activation=\"sigmoid\")(main_lstm)\n",
        "\n",
        "model = Model(inputs=word_in, outputs=out)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_word, y,batch_size=32, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20192/20192 [==============================] - 130s 6ms/step - loss: 0.3183 - accuracy: 0.8613\n",
            "Epoch 2/5\n",
            "20192/20192 [==============================] - 126s 6ms/step - loss: 0.0451 - accuracy: 0.9857\n",
            "Epoch 3/5\n",
            "20192/20192 [==============================] - 128s 6ms/step - loss: 0.0119 - accuracy: 0.9963\n",
            "Epoch 4/5\n",
            "20192/20192 [==============================] - 126s 6ms/step - loss: 0.0072 - accuracy: 0.9976\n",
            "Epoch 5/5\n",
            "20192/20192 [==============================] - 126s 6ms/step - loss: 0.0077 - accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMvkuIetat5u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c0c46f03-e257-41f1-9c65-57e73594ac07"
      },
      "source": [
        "results = model.evaluate(X_test, test_y, batch_size=32)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 0s 680us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1701254873275757, 0.8059999942779541]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swk17QTRDHvE"
      },
      "source": [
        "### diger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VagRP7e48veX"
      },
      "source": [
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, BatchNormalization\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hCyHjVrHdQ7"
      },
      "source": [
        "### diger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhh6MG6d9jep"
      },
      "source": [
        "lr = 1e-4\n",
        "lr_d = 0\n",
        "units = 128\n",
        "dr = 0.5\n",
        "\n",
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=False)(word_in)\n",
        "x1 = SpatialDropout1D(dr)(emb_word)\n",
        "x_gru = Bidirectional(LSTM(units, return_sequences = True))(x1)\n",
        "x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
        "max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
        "    \n",
        "x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "avg_pool3_gru = GlobalAveragePooling1D()(x3)\n",
        "max_pool3_gru = GlobalMaxPooling1D()(x3)\n",
        "    \n",
        "x_lstm = Bidirectional(LSTM(units, return_sequences = True))(x1)\n",
        "x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
        "max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
        "    \n",
        "x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n",
        "max_pool3_lstm = GlobalMaxPooling1D()(x3)\n",
        "    \n",
        "    \n",
        "x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru, avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(Dense(128,activation='relu') (x))\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(Dense(100,activation='relu') (x))\n",
        "x = Dense(1, activation = \"sigmoid\")(x)\n",
        "model = Model(inputs = word_in, outputs = x)\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FRcZw3RAed5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgrlqTsGA_67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "4648e36e-d610-464d-bcb4-7b298e97f346"
      },
      "source": [
        "history = model.fit(X_word, y, batch_size=32, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20192/20192 [==============================] - 144s 7ms/step - loss: 0.6351 - accuracy: 0.6525\n",
            "Epoch 2/5\n",
            "20192/20192 [==============================] - 142s 7ms/step - loss: 0.5441 - accuracy: 0.7347\n",
            "Epoch 3/5\n",
            "20192/20192 [==============================] - 147s 7ms/step - loss: 0.5187 - accuracy: 0.7553\n",
            "Epoch 4/5\n",
            "20192/20192 [==============================] - 143s 7ms/step - loss: 0.5022 - accuracy: 0.7640\n",
            "Epoch 5/5\n",
            "20192/20192 [==============================] - 143s 7ms/step - loss: 0.4964 - accuracy: 0.7640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNv3PGsJJjU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "33ceb641-58c8-4a9f-b4ad-d103e10f3eca"
      },
      "source": [
        "results = model.evaluate(X_test, test_y, batch_size=32)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.523495970249176, 0.7720000147819519]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo-OXszgJjyg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzoNS434JlMw"
      },
      "source": [
        "### diger model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T46aCasYBaZs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "23c7dd63-fc0b-4a75-8b97-530a3dbda3db"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=False)(word_in)\n",
        "\n",
        "dr1 = Dropout(0.2)(emb_word)\n",
        "dr2 = Conv1D(64, 5, activation='relu')(dr1)\n",
        "dr3 = MaxPooling1D(pool_size=4)(dr2)\n",
        "dr4 = Bidirectional(LSTM(300, return_sequences=False))(dr3)\n",
        "output = Dense(1, activation='sigmoid')(dr4)\n",
        "model = Model(inputs=word_in, outputs=output)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_word, y, batch_size=32, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20192/20192 [==============================] - 55s 3ms/step - loss: 0.4602 - accuracy: 0.7832\n",
            "Epoch 2/5\n",
            "20192/20192 [==============================] - 53s 3ms/step - loss: 0.3271 - accuracy: 0.8570\n",
            "Epoch 3/5\n",
            "20192/20192 [==============================] - 53s 3ms/step - loss: 0.2436 - accuracy: 0.8978\n",
            "Epoch 4/5\n",
            "20192/20192 [==============================] - 53s 3ms/step - loss: 0.1708 - accuracy: 0.9314\n",
            "Epoch 5/5\n",
            "20192/20192 [==============================] - 53s 3ms/step - loss: 0.1281 - accuracy: 0.9475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwTOFk-_T6Gs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "837a1108-edd1-4ea2-ea05-7241bdaf8e5f"
      },
      "source": [
        "results = model.evaluate(X_test, test_y, batch_size=32)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 0s 933us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9650347566604615, 0.7039999961853027]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hERO5IL9ni4f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXMTagN8aTW5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU4CHLbAaUDL"
      },
      "source": [
        "# CHAR + SUBWORD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ckv2FRJIKpr"
      },
      "source": [
        "space = \" \"\n",
        "nums = \"0123456789\"\n",
        "punct = \"()+-\\\"?!,.;:'#@\"\n",
        "alphabet = \"aâbcçdefgğhıijklmnoöprsştvwuüyz\"\n",
        "chars = space + nums + punct + alphabet "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRo9TgpIxyS"
      },
      "source": [
        "n_chars = len(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yk_0H1wHeZm"
      },
      "source": [
        "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char2idx[\"UNK\"] = 1\n",
        "char2idx[\"PAD\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATCoMaby0m86"
      },
      "source": [
        "MAX_LEN_CHAR = 25\n",
        "\n",
        "X_char = []\n",
        "for sentence in sequences:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        word_seq = []\n",
        "        for j in range(MAX_LEN_CHAR):\n",
        "            try:\n",
        "                word_seq.append(char2idx.get(sentence.lower()[i][j]))\n",
        "            except:\n",
        "                word_seq.append(char2idx.get(\"PAD\"))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_char.append(np.array(sent_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msWMcUnB0nPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "6a3950cc-71db-499d-aa2f-2a7212e8f2fe"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "\n",
        "\n",
        "char_in = Input(shape=(MAX_LEN, MAX_LEN_CHAR,))\n",
        "emb_char = Embedding(input_dim=n_chars + 2, output_dim=10,\n",
        "                           input_length=MAX_LEN_CHAR, mask_zero=True)(char_in)\n",
        "# character LSTM to get word encodings by characters\n",
        "char_enc = LSTM(units=20, return_sequences=False, recurrent_dropout=0.3)(emb_char)\n",
        "\n",
        "# main LSTM\n",
        "char_enc = GlobalMaxPool1D()(char_enc)\n",
        "\n",
        "x = concatenate([emb_word, char_enc])\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "main_lstm = Bidirectional(LSTM(units=50, return_sequences=False,\n",
        "                               recurrent_dropout=0.3))(x)\n",
        "out = Dense(2, activation=\"sigmoid\")(main_lstm)\n",
        "\n",
        "model = Model([word_in, char_in], out)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, decay=lr_d), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-191-2ad2f21a1439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchar_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN_CHAR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m emb_char = Embedding(input_dim=n_chars + 2, output_dim=10,\n\u001b[0;32m----> 7\u001b[0;31m                            input_length=MAX_LEN_CHAR, mask_zero=True)(char_in)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# character LSTM to get word encodings by characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mchar_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m             if all([s is not None\n\u001b[1;32m    505\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 raise ValueError(\n\u001b[1;32m    129\u001b[0m                     \u001b[0;34m'\"input_length\" is %s, but received input has shape %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     (str(self.input_length), str(input_shape)))\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \"input_length\" is 25, but received input has shape (None, 60, 25)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmP84AS80ngC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "7d962581-78ef-4fd7-c511-35ba649a76e0"
      },
      "source": [
        "history = model.fit([X_word,\n",
        "                     np.array(X_char).reshape((len(X_char), MAX_LEN, MAX_LEN_CHAR))],\n",
        "                    y,\n",
        "                    batch_size=32, epochs=10, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4461 samples, validate on 496 samples\n",
            "Epoch 1/10\n",
            "4461/4461 [==============================] - 109s 24ms/step - loss: 0.6914 - acc: 0.7724 - val_loss: 0.6893 - val_acc: 0.8048\n",
            "Epoch 2/10\n",
            "4461/4461 [==============================] - 91s 20ms/step - loss: 0.6878 - acc: 0.7729 - val_loss: 0.6854 - val_acc: 0.8048\n",
            "Epoch 3/10\n",
            "3008/4461 [===================>..........] - ETA: 29s - loss: 0.6848 - acc: 0.7739"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-dd05ba01a0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                      np.array(X_char).reshape((len(X_char), MAX_LEN, MAX_LEN_CHAR))],\n\u001b[1;32m      3\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L12VshPv9ZIz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ5Up-L69ZsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "245077ee-21eb-44ba-fd3a-eaff908f9332"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "\n",
        "\n",
        "char_in = Input(shape=(MAX_LEN, MAX_LEN_CHAR,))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
        "                           input_length=MAX_LEN_CHAR, mask_zero=True))(char_in)\n",
        "# character LSTM to get word encodings by characters\n",
        "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
        "                                recurrent_dropout=0.3))(emb_char)\n",
        "# main LSTM\n",
        "x = concatenate([emb_word, char_enc])\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "main_lstm = Bidirectional(LSTM(units=20, return_sequences=False,\n",
        "                               recurrent_dropout=0.3))(x)\n",
        "out = Dense(6, activation=\"relu\")(main_lstm)\n",
        "\n",
        "model = Model([word_in, char_in], out)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit([X_word,\n",
        "                     np.array(X_char).reshape((len(X_char), MAX_LEN, MAX_LEN_CHAR))],\n",
        "                    y,\n",
        "                    batch_size=32, epochs=10, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4461 samples, validate on 496 samples\n",
            "Epoch 1/10\n",
            "4461/4461 [==============================] - 123s 28ms/step - loss: 3.6607 - acc: 0.7729 - val_loss: 3.1467 - val_acc: 0.8048\n",
            "Epoch 2/10\n",
            "4461/4461 [==============================] - 104s 23ms/step - loss: 3.6607 - acc: 0.7729 - val_loss: 3.1467 - val_acc: 0.8048\n",
            "Epoch 3/10\n",
            "4461/4461 [==============================] - 104s 23ms/step - loss: 3.6607 - acc: 0.7729 - val_loss: 3.1467 - val_acc: 0.8048\n",
            "Epoch 4/10\n",
            "1472/4461 [========>.....................] - ETA: 1:07 - loss: 3.6061 - acc: 0.7763"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-8f39650c520f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                      np.array(X_char).reshape((len(X_char), MAX_LEN, MAX_LEN_CHAR))],\n\u001b[1;32m     23\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi9VIi4X0oJy"
      },
      "source": [
        "for ex in examples:\n",
        "    tt = tok.texts_to_sequences([ex])\n",
        "    ptt = pad_sequences(tt, MAX_LEN, padding=\"post\")\n",
        "    pred = model.predict(ptt)\n",
        "    print(ex)\n",
        "    show_pred(pred[0])\n",
        "    print(\"---------------\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwyeHpkA9YRj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xJS0Ixz5pTh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "45c2b47b-2a57-4bdf-88fe-b324fc1d8a62"
      },
      "source": [
        "from keras.layers import SpatialDropout1D\n",
        "\n",
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "\n",
        "\n",
        "char_in = Input(shape=(MAX_LEN, MAX_LEN_CHAR,))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
        "                           input_length=MAX_LEN_CHAR, mask_zero=True))(char_in)\n",
        "# character LSTM to get word encodings by characters\n",
        "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
        "                                recurrent_dropout=0.3))(emb_char)\n",
        "# main LSTM\n",
        "x = concatenate([emb_word, char_enc])\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "main_lstm = Bidirectional(LSTM(units=50, return_sequences=False,\n",
        "                               recurrent_dropout=0.3))(x)\n",
        "out = Dense(1, activation=\"softmax\")(main_lstm)\n",
        "\n",
        "model = Model([word_in, char_in], out)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit([X_word,\n",
        "                     np.array(X_char).reshape((len(X_char), MAX_LEN, MAX_LEN_CHAR))],\n",
        "                    y,\n",
        "                    batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16910/16910 [==============================] - 136s 8ms/step - loss: 13.9269 - accuracy: 0.0917\n",
            "Epoch 2/10\n",
            " 9088/16910 [===============>..............] - ETA: 1:02 - loss: 13.8957 - accuracy: 0.0938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-300-c4f0fb8bfaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                      np.array(X_char).reshape((len(X_char), MAX_LEN, MAX_LEN_CHAR))],\n\u001b[1;32m     25\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     batch_size=32, epochs=10, verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDflK2ewmq71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bd677bbb-c839-4f15-8ed3-a1e04d755de1"
      },
      "source": [
        "X_test_char = []\n",
        "for sentence in test_sequences:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        word_seq = []\n",
        "        for j in range(MAX_LEN_CHAR):\n",
        "            try:\n",
        "                word_seq.append(char2idx.get(sentence.lower()[i][j]))\n",
        "            except:\n",
        "                word_seq.append(char2idx.get(\"PAD\"))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_test_char.append(np.array(sent_seq))\n",
        "  \n",
        "results = model.evaluate([X_test, np.array(X_test_char).reshape((len(X_test_char), MAX_LEN, MAX_LEN_CHAR))], test_y, batch_size=32)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.346159253801618, 0.255952388048172]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ4Is6p_cBMO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYcVJD-jcCHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "6bfef66b-eece-4406-cdea-b18dff78ef68"
      },
      "source": [
        "!wget vectors.nlpl.eu/repository/11/174.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 21:26:28--  http://vectors.nlpl.eu/repository/11/174.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473509943 (452M) [application/zip]\n",
            "Saving to: ‘174.zip’\n",
            "\n",
            "174.zip             100%[===================>] 451.57M  20.7MB/s    in 28s     \n",
            "\n",
            "2020-02-15 21:26:57 (16.1 MB/s) - ‘174.zip’ saved [473509943/473509943]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWM5aBqScM-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "61894d9b-7592-4d60-a536-1b68c8ec6a1e"
      },
      "source": [
        "!git clone https://github.com/HIT-SCIR/ELMoForManyLangs.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ELMoForManyLangs'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Total 174 (delta 0), reused 0 (delta 0), pack-reused 174\u001b[K\n",
            "Receiving objects: 100% (174/174), 83.75 KiB | 1.74 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5oUVcnzcaXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c4cb17f-e2a4-4bec-ed1e-93b2305630eb"
      },
      "source": [
        "%cd ELMoForManyLangs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ELMoForManyLangs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FsDq8lseiH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46184653-fd49-444f-a514-a41b451c1d5e"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating elmoformanylangs.egg-info\n",
            "writing elmoformanylangs.egg-info/PKG-INFO\n",
            "writing dependency_links to elmoformanylangs.egg-info/dependency_links.txt\n",
            "writing requirements to elmoformanylangs.egg-info/requires.txt\n",
            "writing top-level names to elmoformanylangs.egg-info/top_level.txt\n",
            "writing manifest file 'elmoformanylangs.egg-info/SOURCES.txt'\n",
            "writing manifest file 'elmoformanylangs.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/__init__.py -> build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/utils.py -> build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/dataloader.py -> build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/__main__.py -> build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/biLM.py -> build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/frontend.py -> build/lib/elmoformanylangs\n",
            "copying elmoformanylangs/elmo.py -> build/lib/elmoformanylangs\n",
            "creating build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/lstm_cell_with_projection.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/encoder_base.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/lstm.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/util.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/classify_layer.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/__init__.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/embedding_layer.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/token_embedder.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/highway.py -> build/lib/elmoformanylangs/modules\n",
            "copying elmoformanylangs/modules/elmo.py -> build/lib/elmoformanylangs/modules\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "copying build/lib/elmoformanylangs/__init__.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "copying build/lib/elmoformanylangs/utils.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "copying build/lib/elmoformanylangs/dataloader.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "copying build/lib/elmoformanylangs/__main__.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "copying build/lib/elmoformanylangs/biLM.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "copying build/lib/elmoformanylangs/frontend.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "creating build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/lstm_cell_with_projection.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/encoder_base.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/lstm.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/util.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/classify_layer.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/__init__.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/embedding_layer.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/token_embedder.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/highway.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/modules/elmo.py -> build/bdist.linux-x86_64/egg/elmoformanylangs/modules\n",
            "copying build/lib/elmoformanylangs/elmo.py -> build/bdist.linux-x86_64/egg/elmoformanylangs\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/dataloader.py to dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/biLM.py to biLM.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/frontend.py to frontend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/lstm_cell_with_projection.py to lstm_cell_with_projection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/encoder_base.py to encoder_base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/lstm.py to lstm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/util.py to util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/classify_layer.py to classify_layer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/embedding_layer.py to embedding_layer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/token_embedder.py to token_embedder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/highway.py to highway.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/modules/elmo.py to elmo.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/elmoformanylangs/elmo.py to elmo.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying elmoformanylangs.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying elmoformanylangs.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying elmoformanylangs.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying elmoformanylangs.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying elmoformanylangs.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/elmoformanylangs-0.0.2-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing elmoformanylangs-0.0.2-py3.6.egg\n",
            "Copying elmoformanylangs-0.0.2-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding elmoformanylangs 0.0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/elmoformanylangs-0.0.2-py3.6.egg\n",
            "Processing dependencies for elmoformanylangs==0.0.2\n",
            "Searching for overrides\n",
            "Reading https://pypi.org/simple/overrides/\n",
            "Downloading https://files.pythonhosted.org/packages/72/dd/ac49f9c69540d7e09210415801a05d0a54d4d0ca8401503c46847dacd3a0/overrides-2.8.0.tar.gz#sha256=2ee4055a686a3ab30621deca01e43562e97825e29b7993e66d73f287d204e868\n",
            "Best match: overrides 2.8.0\n",
            "Processing overrides-2.8.0.tar.gz\n",
            "Writing /tmp/easy_install-y25xx9wr/overrides-2.8.0/setup.cfg\n",
            "Running overrides-2.8.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-y25xx9wr/overrides-2.8.0/egg-dist-tmp-odq3ai42\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving overrides-2.8.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding overrides 2.8.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/overrides-2.8.0-py3.6.egg\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.8.0\n",
            "Best match: h5py 2.8.0\n",
            "Adding h5py 2.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.4.0\n",
            "Best match: torch 1.4.0\n",
            "Adding torch 1.4.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for elmoformanylangs==0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7m1lykXdAMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "93520c54-3439-47cb-e95f-83915db9a494"
      },
      "source": [
        "!unzip 174.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  174.zip\n",
            "  inflating: char.dic                \n",
            "  inflating: config.json             \n",
            "  inflating: encoder.pkl             \n",
            "  inflating: meta.json               \n",
            "  inflating: README                  \n",
            "  inflating: token_embedder.pkl      \n",
            "  inflating: word.dic                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqPOQ6EIe-uR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbebd3e8-af67-4928-fddb-a6f0e3c921bf"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfBS3yYHfEsB"
      },
      "source": [
        "!mkdir turc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRnm6TS7bww4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cb5b16ac-149c-4fa4-9dab-d6ef028a85ca"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "174.zip    config.json\t     meta.json\t  token_embedder.pkl\n",
            "174.zip.1  ELMoForManyLangs  README\t  turc\n",
            "char.dic   encoder.pkl\t     sample_data  word.dic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIZnGy3Fb0dn"
      },
      "source": [
        "!mv char.dic encoder.pkl config.json meta.json README token_embedder.pkl word.dic turc/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX68xxuTcARS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3fc3c967-7c1b-4275-a699-defb7f492966"
      },
      "source": [
        "!ls turc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "char.dic\t\t\t config.json  meta.json  token_embedder.pkl\n",
            "cnn_50_100_512_4096_sample.json  encoder.pkl  README\t word.dic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKG_fBP6fRG_"
      },
      "source": [
        "from elmoformanylangs import Embedder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGKEF1NHi0Fz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "fd306a60-57a2-4726-a675-4271f1b96002"
      },
      "source": [
        "e = Embedder('turc/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-15 22:02:34,909 INFO: char embedding size: 2518\n",
            "2020-02-15 22:02:36,844 INFO: word embedding size: 327303\n",
            "2020-02-15 22:02:41,475 INFO: Model(\n",
            "  (token_embedder): ConvTokenEmbedder(\n",
            "    (word_emb_layer): EmbeddingLayer(\n",
            "      (embedding): Embedding(327303, 100, padding_idx=3)\n",
            "    )\n",
            "    (char_emb_layer): EmbeddingLayer(\n",
            "      (embedding): Embedding(2518, 50, padding_idx=2515)\n",
            "    )\n",
            "    (convolutions): ModuleList(\n",
            "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
            "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
            "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
            "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
            "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
            "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
            "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
            "    )\n",
            "    (highways): Highway(\n",
            "      (_layers): ModuleList(\n",
            "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
            "  )\n",
            "  (encoder): ElmobiLm(\n",
            "    (forward_layer_0): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (backward_layer_0): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (forward_layer_1): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (backward_layer_1): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoJDD71pkQqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "1f3cf1d6-2fed-47e0-c834-79385a427935"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/HIT-SCIR/ELMoForManyLangs/master/configs/cnn_50_100_512_4096_sample.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 21:28:30--  https://raw.githubusercontent.com/HIT-SCIR/ELMoForManyLangs/master/configs/cnn_50_100_512_4096_sample.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 474 [text/plain]\n",
            "Saving to: ‘cnn_50_100_512_4096_sample.json’\n",
            "\n",
            "\r          cnn_50_10   0%[                    ]       0  --.-KB/s               \rcnn_50_100_512_4096 100%[===================>]     474  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-15 21:28:30 (75.0 MB/s) - ‘cnn_50_100_512_4096_sample.json’ saved [474/474]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CqDF2ixcEnK"
      },
      "source": [
        "!mv cnn_50_100_512_4096_sample.json turc/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBjxKuVufy_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "333944ce-f141-4039-ff03-3db5319bf67f"
      },
      "source": [
        "sents = [\"dun oraya gittim ama sen ypoktun beki de vardin benki de yoktun\", \"sen karisma bu ise\"]\n",
        "k = e.sents2elmo(sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-15 21:30:46,582 INFO: 1 batches, avg len: 42.5\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeBfxDL5m9SE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fdf4fd6-215a-4519-a233-f12d1c062cfb"
      },
      "source": [
        "X_sent = e.sents2elmo(sentences[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-15 22:38:20,998 INFO: 2 batches, avg len: 47.4\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqJla5D9q2va"
      },
      "source": [
        "inp = Input(shape = (1,))\n",
        "emb = Embedding(input_dim=n_words+1, output_dim=20, trainable=True)(inp)\n",
        "#l_cov1= Conv2D(128, 5, activation='relu')(inp)\n",
        "#l_pool1 = MaxPooling1D(5)(inp)\n",
        "#l_flat = Flatten()(inp)\n",
        "l_dense = Dense(128, activation='relu')(emb)\n",
        "preds = Dense(2, activation='sigmoid')(l_dense)\n",
        "model = Model(inputs=inp, outputs=preds)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kos44dPsNOq"
      },
      "source": [
        "z = y[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zA6xTog65G5"
      },
      "source": [
        "from keras.layers import Conv1D , Flatten, Conv2D, MaxPooling1D, Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu4zqbvi80dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "855481c8-4138-43a0-9706-cad3cce86ff1"
      },
      "source": [
        "history = model.fit(X_sent, z, validation_split=0.1, batch_size=64, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-6a65ce181d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 100 arrays: [array([[-0.16683054, -0.18544747, -0.33900142, ..., -1.42777   ,\n        -1.2774488 , -1.5696238 ],\n       [-0.7520793 , -0.37188864, -0.24696203, ..., -1.5554692 ,\n        -0.95066094, -0.08072671],..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsMulTU79cUD"
      },
      "source": [
        "@tf.function\n",
        "def ElmoEmbedding(x):\n",
        "        return tf.convert_to_tensor(e.sents2elmo(x)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bieHTVvY9kM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "1e32a2cb-b033-4206-dacc-cac182a41fea"
      },
      "source": [
        "input_text = Input(shape=(120,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(None, 120, 1024))(input_text)\n",
        "l_dense = Dense(128, activation='relu')(embedding)\n",
        "preds = Dense(2, activation='sigmoid')(l_dense)\n",
        "model = Model(inputs=inp, outputs=preds)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-fa5c11e83c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElmoEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ml_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    390\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    391\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 392\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2036\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2038\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2039\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-65-0fa7952138f7>:3 ElmoEmbedding  *\n        return tf.convert_to_tensor(e.sents2elmo(x)[0])\n    /usr/local/lib/python3.6/dist-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/elmo.py:175 sents2elmo  *\n        test, text = read_function(sents, self.config['token_embedder']['max_characters_per_token'])\n    /usr/local/lib/python3.6/dist-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/elmo.py:37 read_list  *\n        if max_chars is not None and len(token) + 2 > max_chars:\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py:396 converted_call\n        return py_builtins.overload_of(f)(*args)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/py_builtins.py:209 len_\n        return _tf_tensor_len(s)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/py_builtins.py:235 _tf_tensor_len\n        'len requires a non-scalar tensor, got one of shape {}'.format(shape))\n\n    ValueError: len requires a non-scalar tensor, got one of shape Tensor(\"Shape:0\", shape=(0,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYfphYZnEkI-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbSEvM87CTG7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4cIUmXw2LNA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1QHAF1i2ZSD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}